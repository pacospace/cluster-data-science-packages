{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+12\"><center>\n",
    "    Data Science Packages Latent Dirichlet Allocation (LDA) Hyperparameters Tuning\n",
    "</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from gensim import corpora, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_PERCENTAGE_TEST_DATASET = 0.1 or os.getenv(\"LDA_PERCENTAGE_TEST_DATASET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 2949\n",
      "Training Dataset percentage is: 90\n",
      "Test Dataset percentage is: 10\n"
     ]
    }
   ],
   "source": [
    "# Retrieve clean dataset\n",
    "current_path = Path.cwd().parents[0]\n",
    "data_path = current_path.joinpath(\"data/processed\")\n",
    "\n",
    "with open(f\"{data_path}/clean_dataset.json\") as json_file:\n",
    "    clean_dataset = json.load(json_file)\n",
    "\n",
    "texts_names = []\n",
    "texts = []\n",
    "for file_name, file_vocabulary in clean_dataset.items():\n",
    "    texts.append(file_vocabulary)\n",
    "    texts_names.append(file_name)\n",
    "\n",
    "# Process data for LDA\n",
    "    \n",
    "# Assign a unique integer id to all words appearing in the corpus, creating a vocabulary corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(\"Number of unique tokens: %d\" % len(dictionary))\n",
    "# print(f\"Token ID map:\\n {dictionary.token2id}\")\n",
    "\n",
    "# Bag of Words (BoW) Representation\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in texts]\n",
    "\n",
    "lda_percentage_training_dataset = (1 - float(LDA_PERCENTAGE_TEST_DATASET)) * 100\n",
    "print(\"Training Dataset percentage is: %d\" % lda_percentage_training_dataset)\n",
    "\n",
    "lda_percentage_test_dataset = float(LDA_PERCENTAGE_TEST_DATASET) * 100\n",
    "print(\"Test Dataset percentage is: %d\" % lda_percentage_test_dataset)\n",
    "\n",
    "corpus_train, corpus_test = train_test_split(corpus, test_size=LDA_PERCENTAGE_TEST_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inputs for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of topics selected between 10 and 10 with step 1\n",
      "Total number of LDA run: 9\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "step_size = 1\n",
    "\n",
    "# Number of topics\n",
    "NUMBER_TOPICS_MIN = int(os.getenv(\"NUMBER_TOPICS\", 10))\n",
    "NUMBER_TOPICS_MAX = int(os.getenv(\"NUMBER_TOPICS\", 10))\n",
    "\n",
    "topics_range = range(NUMBER_TOPICS_MIN, NUMBER_TOPICS_MAX + step_size, step_size)\n",
    "\n",
    "print(f\"Range of topics selected between {NUMBER_TOPICS_MIN} and {NUMBER_TOPICS_MAX} with step {step_size}\")\n",
    "\n",
    "# ALPHA: Dirichlet hyperparameter alpha, Document-Topic Density.\n",
    "\n",
    "alpha_step = 0.8\n",
    "\n",
    "# alpha controls the mixture of topics for any given document. \n",
    "# Turn it down, and the documents will likely have less of a mixture of topics.\n",
    "# Turn it up, and the documents will likely have more of a mixture of topics.\n",
    "LDA_ALPHA_MIN = os.getenv(\"LDA_ALPHA\", 0.2)\n",
    "LDA_ALPHA_MAX = os.getenv(\"LDA_ALPHA\", 1)\n",
    "\n",
    "alpha_spectrum = list(np.arange(LDA_ALPHA_MIN, LDA_ALPHA_MAX, alpha_step))\n",
    "alpha_spectrum.append(\"symmetric\")\n",
    "alpha_spectrum.append(\"asymmetric\")\n",
    "\n",
    "# ETA: Dirichlet hyperparameter alpha, Topic-Word Density.\n",
    "\n",
    "eta_step = 0.8\n",
    "    \n",
    "# The beta/eta hyperparameter controls the distribution of words per topic.\n",
    "# Turn it down, and the topics will likely have less words.\n",
    "# Turn it up, and the topics will likely have more words.\n",
    "LDA_ETA_MIN = os.getenv(\"LDA_ETA\", 0.001)\n",
    "LDA_ETA_MAX = os.getenv(\"LDA_ETA\", 1)\n",
    "\n",
    "eta_spectrum = list(np.arange(LDA_ETA_MIN, LDA_ETA_MAX, eta_step))\n",
    "eta_spectrum.append(\"symmetric\")\n",
    "\n",
    "# Ideally, we want our composites to be made up of only a few topics\n",
    "# and our parts to belong to only some of the topics. With this in mind,\n",
    "# alpha and beta are typically set below one.\n",
    "\n",
    "# Number of passes through the corpus during training.\n",
    "passes = 100\n",
    "\n",
    "# Maximum number of iterations through the corpus\n",
    "# when inferring the topic distribution of a corpus.\n",
    "iterations = 200\n",
    "\n",
    "# Number of documents to be used in each training chunk.\n",
    "chunksize = 100\n",
    "\n",
    "total = len(topics_range) * len(alpha_spectrum) * len(eta_spectrum)\n",
    "print(f\"Total number of LDA run: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def _evaluate_metrics(\n",
    "    ldamodel,\n",
    "    corpus,\n",
    "    texts,\n",
    "    dictionary,\n",
    "):\n",
    "    \"\"\"Evaluate metrics for the LDA model trained.\"\"\"\n",
    "    # Model Perplexity, a measure of how good the model is. lower the better.\n",
    "    perplexity = ldamodel.log_perplexity(corpus)\n",
    "    perplexity_exponential = math.exp(perplexity)\n",
    "\n",
    "    # Coherence measure\n",
    "    COHERENCE_MEASURE = \"c_v\" or os.getenv(\"COHERENCE\")\n",
    "\n",
    "    print(f\"\\nCoherence quantity used is: {COHERENCE_MEASURE}\")\n",
    "    # Model Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=ldamodel, texts=texts, dictionary=dictionary, coherence=COHERENCE_MEASURE\n",
    "    )\n",
    "    coherence = coherence_model_lda.get_coherence()\n",
    "    print(f\"\\nCoherence Score: {coherence}\")\n",
    "\n",
    "    return perplexity, coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [02:06<04:13, 42.21s/it]\n",
      " 11%|█         | 1/9 [00:15<02:04, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.29450834482470023\n",
      "Number of Topics 10\n",
      "Alpha 0.2 and eta 0.001\n",
      "Perplexity -44.3736509631979\n",
      "Coherence 0.29450834482470023\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:28<01:39, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.43583886574624325\n",
      "Number of Topics 10\n",
      "Alpha 0.2 and eta 0.801\n",
      "Perplexity -7.823765027819895\n",
      "Coherence 0.43583886574624325\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:44<01:29, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.42709673702023887\n",
      "Number of Topics 10\n",
      "Alpha 0.2 and eta symmetric\n",
      "Perplexity -8.169935648876049\n",
      "Coherence 0.42709673702023887\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:59<01:15, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.3077708500093541\n",
      "Number of Topics 10\n",
      "Alpha symmetric and eta 0.001\n",
      "Perplexity -39.51110117086189\n",
      "Coherence 0.3077708500093541\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [01:14<00:59, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.35684465741286636\n",
      "Number of Topics 10\n",
      "Alpha symmetric and eta 0.801\n",
      "Perplexity -7.836504838180229\n",
      "Coherence 0.35684465741286636\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [01:27<00:43, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.38730469733846884\n",
      "Number of Topics 10\n",
      "Alpha symmetric and eta symmetric\n",
      "Perplexity -8.141127914818254\n",
      "Coherence 0.38730469733846884\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [01:43<00:29, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.27951869844049676\n",
      "Number of Topics 10\n",
      "Alpha asymmetric and eta 0.001\n",
      "Perplexity -41.15276883720188\n",
      "Coherence 0.27951869844049676\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [01:57<00:14, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.6182993935883683\n",
      "Number of Topics 10\n",
      "Alpha asymmetric and eta 0.801\n",
      "Perplexity -7.811780744683924\n",
      "Coherence 0.6182993935883683\n",
      "\n",
      "Coherence quantity used is: c_v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:08<00:00, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.3587372475072122\n",
      "Number of Topics 10\n",
      "Alpha asymmetric and eta symmetric\n",
      "Perplexity -8.056136496009634\n",
      "Coherence 0.3587372475072122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Create Hyperparamter repo\n",
    "current_path = Path.cwd().parents[0]\n",
    "\n",
    "hp_model_path = current_path.joinpath(f\"models/hyperparameters_{random.getrandbits(64):08x}\")\n",
    "\n",
    "if not hp_model_path.exists():\n",
    "    os.makedirs(hp_model_path)\n",
    "                \n",
    "pbar = tqdm.tqdm(total=total)\n",
    "\n",
    "for num_topics in topics_range:\n",
    "\n",
    "    for alpha in alpha_spectrum:\n",
    "\n",
    "        for eta in eta_spectrum:\n",
    "            \n",
    "            inputs = {\n",
    "                \"corpus\": corpus,\n",
    "                \"num_topics\": num_topics,\n",
    "                \"id2word\": dictionary,\n",
    "                \"passes\": passes,\n",
    "                \"chunksize\": chunksize,\n",
    "                \"iterations\": iterations,\n",
    "                \"alpha\": alpha,\n",
    "                \"eta\": eta\n",
    "            }\n",
    "            \n",
    "            MODEL_NAME = \"model\" or os.getenv(\"MODEL_NAME\")\n",
    "            model_name = MODEL_NAME + \"_\" + f\"t{num_topics}\" \"_\" + datetime.utcnow().strftime(\n",
    "                \"%Y-%m-%d_%H:%M:%S\"\n",
    "            )\n",
    "            \n",
    "            ldamodel = models.ldamodel.LdaModel(**inputs)\n",
    "\n",
    "            perplexity, coherence = _evaluate_metrics(\n",
    "                ldamodel=ldamodel, corpus=corpus, texts=texts, dictionary=dictionary\n",
    "            )\n",
    "\n",
    "            print(f\"Number of Topics {num_topics}\")\n",
    "            print(f\"Alpha {alpha} and eta {eta}\")\n",
    "            print(f\"Perplexity {perplexity}\")\n",
    "            print(f\"Coherence {coherence}\")\n",
    "\n",
    "            results.append([num_topics, alpha, eta, perplexity, coherence])\n",
    "\n",
    "            complete_results_and_inputs[\"results\"] = results\n",
    "\n",
    "            # Store LDA model\n",
    "            model_repo_path = hp_model_path.joinpath(model_name)\n",
    "\n",
    "            if not model_repo_path.exists():\n",
    "                os.makedirs(model_repo_path)\n",
    "\n",
    "            complete_file_path = model_repo_path.joinpath(f\"{model_name}_lda_model\")\n",
    "\n",
    "            ldamodel.save(str(complete_file_path))\n",
    "            \n",
    "            complete_results_and_inputs = {\n",
    "                \"topics_range\": list(topics_range),\n",
    "                \"alpha_spectrum\": alpha_spectrum,\n",
    "                \"eta_spectrum\": eta_spectrum,\n",
    "                \"results\": results,\n",
    "            }\n",
    "            with open(f\"{hp_model_path}/hypeparameters_inputs.json\", mode=\"w\") as outfile:\n",
    "                json.dump(complete_results_and_inputs, outfile)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics range: range(10, 11)\n",
      "Sorted parameters by coherence n.1: [10, 'asymmetric', 0.801, -7.811780744683924, 0.6182993935883683]\n",
      "Sorted parameters by coherence n.2: [10, 0.2, 0.801, -7.823765027819895, 0.43583886574624325]\n",
      "Sorted parameters by coherence n.3: [10, 0.2, 'symmetric', -8.169935648876049, 0.42709673702023887]\n",
      "Sorted parameters by coherence n.4: [10, 'symmetric', 'symmetric', -8.141127914818254, 0.38730469733846884]\n",
      "Sorted parameters by coherence n.5: [10, 'asymmetric', 'symmetric', -8.056136496009634, 0.3587372475072122]\n",
      "Sorted parameters by coherence n.6: [10, 'symmetric', 0.801, -7.836504838180229, 0.35684465741286636]\n",
      "Sorted parameters by coherence n.7: [10, 'symmetric', 0.001, -39.51110117086189, 0.3077708500093541]\n",
      "Sorted parameters by coherence n.8: [10, 0.2, 0.001, -44.3736509631979, 0.29450834482470023]\n",
      "Sorted parameters by coherence n.9: [10, 'asymmetric', 0.001, -41.15276883720188, 0.27951869844049676]\n",
      "Optimized parameters for 10 topics is: [10, 'asymmetric', 0.801, -7.811780744683924, 0.6182993935883683]\n",
      "Parameters for max coherence: [10, 'asymmetric', 0.801, -7.811780744683924, 0.6182993935883683]\n",
      "Max Num topics: 10\n"
     ]
    }
   ],
   "source": [
    "results = complete_results_and_inputs[\"results\"]\n",
    "# Sort by coeherence\n",
    "results.sort(key=lambda x: x[4], reverse=True)\n",
    "\n",
    "print(f\"Topics range: {topics_range}\")\n",
    "n = 1\n",
    "for result in results:\n",
    "    print(f\"Sorted parameters by coherence n.{n}: {result}\")\n",
    "    n += 1\n",
    "\n",
    "optimized_per_topic = []\n",
    "for topic_number in sorted(topics_range, reverse=True):\n",
    "    for result in results:\n",
    "        if result[0] == topic_number:\n",
    "            optimized_per_topic.append(result)\n",
    "            break\n",
    "\n",
    "optimized_per_topic.sort(key=lambda x: x[4], reverse=True)\n",
    "\n",
    "for optimized in optimized_per_topic:\n",
    "    print(f\"Optimized parameters for {optimized[0]} topics is: {optimized}\")\n",
    "print(f\"Parameters for max coherence: {results[0]}\")\n",
    "print(f\"Max Num topics: {results[0][0]}\")\n",
    "# TODO Add visualizations plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
